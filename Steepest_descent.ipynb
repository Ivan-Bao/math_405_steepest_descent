{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f20197-6a8a-4ebd-abe3-456903fbfbbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MATH 405/607 \n",
    "\n",
    "# Method of Steepest Descent \n",
    "# (Also known as Gradient Descent)\n",
    "\n",
    "* Optimization problems & Root finding\n",
    "* Gradient Descent Scheme\n",
    "* Error Analysis\n",
    "* Global Convergence\n",
    "\n",
    "### Literature \n",
    "\n",
    "* [Boyd and Vandenberghe, Convex Optimization, Chapter 9](https://web.stanford.edu/~boyd/cvxbook/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "795cc739-e637-42f9-9e6b-32ca679c17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module MATH405.\n"
     ]
    }
   ],
   "source": [
    "include(\"math405.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f424287f-c4ae-4d9e-9972-a3d37543a384",
   "metadata": {},
   "source": [
    "## Optimization Problems\n",
    "\n",
    "**Motivation:** Finding the minimum (\"optimum\") points of a function numerically. \n",
    "\n",
    "**Fundamental Principle:** By following the opposite direction of its gradient in each iteration.\n",
    "\n",
    "In other words, step towards where the function decreases the fastest. (\"Steepest\" descent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3464777-4d52-4fbe-858c-0b24ffa8029e",
   "metadata": {},
   "source": [
    "Simple example:\n",
    "\n",
    "Finding the minimum of\n",
    "$$f(x,y) = x^2 + y^2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d29679-27f3-49fa-a6c7-1af25960d686",
   "metadata": {},
   "source": [
    "![GradientDescenturl](https://blog.paperspace.com/content/images/2018/05/68747470733a2f2f707669676965722e6769746875622e696f2f6d656469612f696d672f70617274312f6772616469656e745f64657363656e742e676966.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d22e5c2-7a7a-43ee-b841-a2c9f3e1fc89",
   "metadata": {},
   "source": [
    "### Formulation\n",
    "Given a function $f \\in \\mathbb{R}^M$, which we need to find its minimum.\n",
    "\n",
    "Starting at some initial guess: $U_0 = \\begin{pmatrix} \n",
    "    x_{1, 0} \\\\ x_{2, 0} \\\\ \\vdots \\\\ x_{M, 0}\n",
    "    \\end{pmatrix}$\n",
    "\n",
    "The gradient of the function at this point is given by \n",
    "$$\\nabla f(U_n)= \n",
    "    \\begin{pmatrix} \n",
    "    \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_M}\n",
    "    \\end{pmatrix} \\, \\Bigg|_{\\,U_n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2b305-3cbc-4b7d-8b16-6e5c77f4a522",
   "metadata": {},
   "source": [
    "Then, we define the Gradient Descent Scheme:\n",
    "\n",
    "$$ U_{n+1} = U_n + h\\big( -\\nabla f(U_n)\\big)$$\n",
    "\n",
    "Where $h$ is the step size\n",
    "\n",
    "With the exit condition being $\\lVert \\nabla f(U_k) \\rVert \\leq \\epsilon$ for some small tolerance $\\epsilon$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab240f21-13b1-4278-8263-cea0785c0db7",
   "metadata": {},
   "source": [
    "### Advantage of the Gradient Descent Scheme:\n",
    "\n",
    "* Resilient to not so \"nice\" functions (Whose higher order derivatives does not exist or have unwanted zeros)\n",
    "* Moderate computation complexity (Requires only first order derivative)\n",
    "* Consistent convergence rate & Globally convergent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95768c7f-c4e7-4e4a-80c3-ea686ed05f08",
   "metadata": {},
   "source": [
    "### Comparison to Newton's Method in Optimization ï¼ˆ1-D Case)\n",
    "The Newton's Method of Optimization is defined as \n",
    "$$U_{n+1} = U_n - h\\frac{f'(U_n)}{f''(U_n)}$$\n",
    "(Finding the root of derivative instead of $f^0(x)$)\n",
    "\n",
    "Where the 1-D Gradient Descent Method is \n",
    "$$ U_{n+1} = U_n - hf'(U_n)$$\n",
    "\n",
    "Newton's Method requires $f''(U_n)$ to exist and is well-behaved (no nearby zeros)\n",
    "\n",
    "Where Gradient Descent only requires $f'(U_n)$ to exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d82c08-febc-426a-bc20-63673d613b2b",
   "metadata": {},
   "source": [
    "### Example:\n",
    "Finding the minimum of $f(x) = cos(x)$ within $(0, \\pi)$ \n",
    "\n",
    "##### Newton's Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a34651f-fee1-4bf7-bebf-c0412f861011",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x -> cos(x)\n",
    "df = x -> ForwardDiff.derivative(f, x)\n",
    "d2f = x -> ForwardDiff.derivative(df, x)\n",
    "h = 0.01\n",
    "tolerance = 1e-8;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1507ff34-d43e-4e9a-8d9a-1cd103fe87db",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: plot not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: plot not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[1]:6",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "#guess = pi/2+0.00001 # If you QA Engineer is having a bad day he's gonna do this\n",
    "#Believe or not, this ^^ is so ugly that even Jupyter Lab refused to save the notebook file (throws error 413)\n",
    "guess = pi/2 + 0.1\n",
    "\n",
    "x = guess; iter = [x]\n",
    "p = plot(f, 0.0, 2*pi, lw=3, grid=:xy, size=(800,300))\n",
    "scatter!([x], [f(x)], ms=4, color=:red)\n",
    "while(true)\n",
    "    old_x = x\n",
    "    x -= h * df(x) / d2f(x) ; push!(iter, x)\n",
    "    scatter!([x], [f(x)], ms=4, color=:red)\n",
    "    if abs(old_x - x) <= tolerance\n",
    "        break\n",
    "    end\n",
    "end\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d1df0-2ce0-42f6-a41a-9a927f165d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = pi/2+0.5\n",
    "\n",
    "x = guess; iter = [x]\n",
    "p = plot(f, 0.0, 2*pi, lw=3, grid=:xy, size=(800,300))\n",
    "scatter!([x], [f(x)], ms=4, color=:red)\n",
    "while(true)\n",
    "    old_x = x\n",
    "    x -= h * df(x) ; push!(iter, x)\n",
    "    scatter!([x], [f(x)], ms=4, color=:red)\n",
    "    if abs(old_x - x) <= tolerance\n",
    "        break\n",
    "    end\n",
    "end\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f949084-19ea-444d-9e4b-87986abf5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computational Cost:\n",
    "### L2-regularized Least Sqaures:\n",
    "For the L2-regularized least squares, running t iterations of gradient descent will take O(ndt), n examples and d features.\n",
    "The closed form solution: $w = (X^TX+\\lambda I)^{-1}(X^Ty)$, costs $O(nd^2 + d^3).\n",
    "\n",
    "So gradient descent is only faster if we only have to do $t <$ max$\\{d, d^2/n\\}$ iterations.\n",
    "\n",
    "### Logisitc Regression:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177787bb-5a5c-4538-940c-3ef6af778779",
   "metadata": {},
   "source": [
    "Test Cell adam is gonna put notes in\n",
    "\n",
    "https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf 477-498 are good  \n",
    "https://web.stanford.edu/~boyd/cvxbook/bv_cvxslides.pdf  \n",
    "https://www.osti.gov/servlets/purl/983240/  \n",
    "https://www.cs.ubc.ca/~schmidtm/Courses/540-W18/L4.pdf  \n",
    "https://www.math.usm.edu/lambers/mat419/lecture10.pdf  \n",
    "https://people.seas.harvard.edu/~yaron/AM221-S16/lecture_notes/AM221_lecture10.pdf  \n",
    "\n",
    "\n",
    "General steepest descent methods:\n",
    "    move along the direction that leads to the steepest descent with respect to a certain parameter\n",
    "\n",
    "starting at some intial point $x_0$, we iterate $x_k$ by stepping: \n",
    "$$\n",
    "x_{k+1} = x_k + \\alpha_kd_k\n",
    "$$\n",
    "\n",
    "where $d_k$ is the direction of steepest decrease in the function $f(x)$ and:\n",
    "\n",
    "$$\n",
    "\\alpha_k = \\arg_{\\alpha} \\min f(x_k + \\alpha d_k)\n",
    "$$\n",
    "\n",
    "ex for finding the minima of a function $h(x,y)$:\n",
    "$$\n",
    "f(x,y) = h(x,y)\n",
    "$$\n",
    "ex for finding the solution to an equation $Ax = b$:\n",
    "$$\n",
    "f(x_k) = ||Ax_k-b||\n",
    "$$\n",
    "ex for \n",
    "\n",
    "**Gradient descent**:https://en.wikipedia.org/wiki/Gradient_descent  \n",
    "    descend along the negative gradient of a function to find a local minima.  \n",
    "        requires the function to be differentiable.  \n",
    "    inverse is gradient ascent (finding maxima)\n",
    "   \n",
    "**Coordinate descent**:https://en.wikipedia.org/wiki/Coordinate_descent  \n",
    "    iteratively move along coordinate directions to find a local minima of a function  \n",
    "        does not require differentiability (big plus)  \n",
    "\n",
    "**Conjugate gradient descent**:https://en.wikipedia.org/wiki/Conjugate_gradient_method  \n",
    "\n",
    "\n",
    "**Adaptive coordinate descent**:https://en.wikipedia.org/wiki/Adaptive_coordinate_descent  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93da98b5-6b03-4e24-bbe7-82c6509a7a35",
   "metadata": {},
   "source": [
    "# Descent Methods #\n",
    "## Motivation: Unconstrained minimization problems ##\n",
    "Solving:\n",
    "$$\n",
    "\\min f(x)\n",
    "$$\n",
    "Where $f: \\Re^n \\rightarrow \\Re$. and f is continuously differentiable and has a minimum at the point $x_a$. To make our analysis easier (and ensure there is a minima), for this presentation we will also assume $f$ is **convex**.  \n",
    "### Convex functions ###\n",
    "A function $f$ is convex on an interval $x \\in [x_a,x_b]$ if:\n",
    "$$\n",
    "f(tx_1+(t-1)x_2) \\leq tf(x_1) + (1-t)f(x_2)\n",
    "$$\n",
    "for $t \\in [0,1]$ for any two points on the interval $x_1 \\in [x_a,x_b], x_2 \\in [x_a,x_b], x_1 < x_2$ . Graphically this is equivalent to:\n",
    "![Convex Chord](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/ConvexFunction.svg/1024px-ConvexFunction.svg.png)\n",
    "<em>Source: Wikipedia \"Convex Functions\"</em>\n",
    "for a function to be globally convex it must be true for any $x_1, x_2$. \n",
    "  \n",
    "If a function is convex then the global minimum will be at the point $x_{min}$ such that:\n",
    "$$\n",
    "\\nabla f(x_{min}) = 0\n",
    "$$\n",
    "\n",
    "an example of an important/useful function that are convex are norms.\n",
    "\n",
    "## Strong Concavity ##\n",
    "\n",
    "If a function is said to be strongly concave it satisfies:\n",
    "$$\n",
    "\\nabla^2f(x)\\succeq mI\n",
    "$$\n",
    "$m \\in \\Re$. Which means the matrix $A = \\nabla^2f(x) - mI$ is positive semi-definite ($xAx^T \\geq 0$). In 1 dimension this is equivalent to saying $f''(x) \\geq m$.\n",
    "##  Solving minimization problems: An intuitive approach ##\n",
    "Lets say we have some function $f: \\Re^2 \\rightarrow \\Re$ that we want to find the minimum of numerically, and we can differentiate the function at any point.\n",
    "  \n",
    "An intuitive pseudocode algorithm we could use would be as follows:  \n",
    "\n",
    "1. Starting at $x_0$, find the direction $\\Delta x$ which we can \"move\" from $x_0$ to decrease $f$ (descending)\n",
    "2. \"Move\" in that direction for \"a while\"\n",
    "3. Repeat steps 1 and 2 until we reach the minima\n",
    "\n",
    "This algorithm describes a generic **descent method**.  \n",
    "\n",
    "The direction $\\Delta x$ defines a line in $\\Re^2$ that we will move along.\n",
    "![Steepest Descent Searches](steepestDescentSearchSlice.PNG)\n",
    "\n",
    "The difference between descent methods often involve stopping at different points along the ray defined by the steepest descent line. Given a stopping condition, Step 2 in our algorithm becomes a **searching problem** as we will want to find the point at which we'd like stop along $\\Delta x$ to find the next direction of steepest descent.\n",
    "## Stopping conditions for Descent Method iteration steps ##\n",
    "Two commonly used searches are the **Linear search** and **Backtracking search**\n",
    "### Linear Search ###\n",
    "Evaluate:\n",
    "$$\n",
    "\\arg \\min_t f(x_0 + t\\Delta x)\n",
    "$$\n",
    "Or in $\\Re^2$, find the spot on the line defined by $x + t\\Delta x$ does the function reach a minima? This search method is **exact**. However, numerically this search method can be computationally depending on $f(x)$.\n",
    "\n",
    "### Backtracking search ###\n",
    "**Big idea:** Approximately minimize $f(x)$ along $\\Delta x$\n",
    "Start at $t_0 = 1$ and iterate $t_{n+1} = \\beta t_n$ until:\n",
    "$$\n",
    "f(x_0 +t_n\\Delta x) \\leq f(x_0) + \\alpha \\nabla f(x_0)^T \\Delta x\n",
    "$$\n",
    "Where $\\alpha \\in [0,0.5]$ and $\\beta \\in [0,1]$. This method is **inexact** but is useful for computation when it is costly to compute $f(x)$. Iterations of the descent method using backtracking converges on the minimum point slower than if using an exact search (fewer steps) but may execute faster if $f(x)$ is a costly operation.\n",
    "\n",
    "![backtrack](backtrack.PNG)\n",
    "\n",
    "The reason this converges over many iterations to the minima hinges on the fact that $\\nabla f$ is monotonically approaching zero as we approach the minima since the function is convex. And that each step we take we get a little bit closer to the minima. Another way to see this is that there is a chord formed by the line $f(x_0)+\\alpha t\\nabla f(x_0)^T \\Delta x$ defines the region where the backtracking search can stop. Since $f$ is convex this chord is higher than all the other points between the points where the line intersects the function. This means that the search will only end when it has found a point that is lower than the initial point.\n",
    "\n",
    "## Example Steepest descent methods ##\n",
    "![Steepest Descent Searches](steepestDescentSearch.PNG)\n",
    "\n",
    "## How do we determine the direction of steepest descent? ##\n",
    "The easiest option would be to move in the direction of the **negative gradient** of $f$ (the function we are minimizing):  \n",
    "$$\n",
    "\\Delta x = - \\nabla f(x)\n",
    "$$\n",
    "\n",
    "\n",
    "This would ensure that at each iteration we are always minimizing $f$ at the maximal rate.\n",
    "\n",
    "![Steepest Descent Searches](steepestDescentSearch.PNG)\n",
    "The rays are always rotated $\\frac{\\pi}{2}$ radians from the level curves. This corresponds to following the negative gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d35b6e-8b31-48d1-9875-3f485a268e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
