{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f20197-6a8a-4ebd-abe3-456903fbfbbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MATH 405/607 \n",
    "\n",
    "# Method of Steepest Descent \n",
    "# (Also known as Gradient Descent)\n",
    "\n",
    "* Optimization problems & Root finding\n",
    "* Gradient Descent Scheme\n",
    "* Error Analysis\n",
    "* Global Convergence\n",
    "\n",
    "### Literature \n",
    "\n",
    "* [Boyd and Vandenberghe, Convex Optimization, Chapter 9](https://web.stanford.edu/~boyd/cvxbook/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "795cc739-e637-42f9-9e6b-32ca679c17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module MATH405.\n"
     ]
    }
   ],
   "source": [
    "include(\"math405.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f424287f-c4ae-4d9e-9972-a3d37543a384",
   "metadata": {},
   "source": [
    "## Optimization Problems\n",
    "\n",
    "**Motivation:** Finding the minimum (\"optimum\") points of a function numerically. \n",
    "\n",
    "**Fundamental Principle:** By following the opposite direction of its gradient in each iteration.\n",
    "\n",
    "In other words, step towards where the function decreases the fastest. (\"Steepest\" descent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3464777-4d52-4fbe-858c-0b24ffa8029e",
   "metadata": {},
   "source": [
    "Simple example:\n",
    "\n",
    "Finding the minimum of\n",
    "$$f(x,y) = x^2 + y^2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d29679-27f3-49fa-a6c7-1af25960d686",
   "metadata": {},
   "source": [
    "![GradientDescenturl](https://blog.paperspace.com/content/images/2018/05/68747470733a2f2f707669676965722e6769746875622e696f2f6d656469612f696d672f70617274312f6772616469656e745f64657363656e742e676966.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d22e5c2-7a7a-43ee-b841-a2c9f3e1fc89",
   "metadata": {},
   "source": [
    "### Formulation\n",
    "Given a function $f \\in \\mathbb{R}^M$, which we need to find its minimum.\n",
    "\n",
    "Starting at some initial guess: $U_0 = \\begin{pmatrix} \n",
    "    x_{1, 0} \\\\ x_{2, 0} \\\\ \\vdots \\\\ x_{M, 0}\n",
    "    \\end{pmatrix}$\n",
    "\n",
    "The gradient of the function at this point is given by \n",
    "$$\\nabla f(U_n)= \n",
    "    \\begin{pmatrix} \n",
    "    \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_M}\n",
    "    \\end{pmatrix} \\, \\Bigg|_{\\,U_n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2b305-3cbc-4b7d-8b16-6e5c77f4a522",
   "metadata": {},
   "source": [
    "Then, we define the Gradient Descent Scheme:\n",
    "\n",
    "$$ U_{n+1} = U_n + h\\big( -\\nabla f(U_n)\\big)$$\n",
    "\n",
    "Where $h$ is the step size\n",
    "\n",
    "With the exit condition being $\\lVert \\nabla f(U_k) \\rVert \\leq \\epsilon$ for some small tolerance $\\epsilon$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab240f21-13b1-4278-8263-cea0785c0db7",
   "metadata": {},
   "source": [
    "### Advantage of the Gradient Descent Scheme:\n",
    "\n",
    "* Resilient to not so \"nice\" functions (Whose higher order derivatives does not exist or have unwanted zeros)\n",
    "* Moderate computation complexity (Requires only first order derivative)\n",
    "* Consistent convergence rate & Globally convergent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95768c7f-c4e7-4e4a-80c3-ea686ed05f08",
   "metadata": {},
   "source": [
    "### Comparison to Newton's Method in Optimization ï¼ˆ1-D Case)\n",
    "The Newton's Method of Optimization is defined as \n",
    "$$U_{n+1} = U_n - h\\frac{f'(U_n)}{f''(U_n)}$$\n",
    "(Finding the root of derivative instead of $f^0(x)$)\n",
    "\n",
    "Where the 1-D Gradient Descent Method is \n",
    "$$ U_{n+1} = U_n - hf'(U_n)$$\n",
    "\n",
    "Newton's Method requires $f''(U_n)$ to exist and is well-behaved (no nearby zeros)\n",
    "\n",
    "Where Gradient Descent only requires $f'(U_n)$ to exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d82c08-febc-426a-bc20-63673d613b2b",
   "metadata": {},
   "source": [
    "### Example:\n",
    "Finding the minimum of $f(x) = cos(x)$ within $(0, \\pi)$ \n",
    "\n",
    "##### Newton's Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a34651f-fee1-4bf7-bebf-c0412f861011",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x -> cos(x)\n",
    "df = x -> ForwardDiff.derivative(f, x)\n",
    "d2f = x -> ForwardDiff.derivative(df, x)\n",
    "h = 0.01\n",
    "tolerance = 1e-8;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1507ff34-d43e-4e9a-8d9a-1cd103fe87db",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: plot not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: plot not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[1]:6",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "#guess = pi/2+0.00001 # If you QA Engineer is having a bad day he's gonna do this\n",
    "#Believe or not, this ^^ is so ugly that even Jupyter Lab refused to save the notebook file (throws error 413)\n",
    "guess = pi/2 + 0.1\n",
    "\n",
    "x = guess; iter = [x]\n",
    "p = plot(f, 0.0, 2*pi, lw=3, grid=:xy, size=(800,300))\n",
    "scatter!([x], [f(x)], ms=4, color=:red)\n",
    "while(true)\n",
    "    old_x = x\n",
    "    x -= h * df(x) / d2f(x) ; push!(iter, x)\n",
    "    scatter!([x], [f(x)], ms=4, color=:red)\n",
    "    if abs(old_x - x) <= tolerance\n",
    "        break\n",
    "    end\n",
    "end\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d1df0-2ce0-42f6-a41a-9a927f165d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = pi/2+0.5\n",
    "\n",
    "x = guess; iter = [x]\n",
    "p = plot(f, 0.0, 2*pi, lw=3, grid=:xy, size=(800,300))\n",
    "scatter!([x], [f(x)], ms=4, color=:red)\n",
    "while(true)\n",
    "    old_x = x\n",
    "    x -= h * df(x) ; push!(iter, x)\n",
    "    scatter!([x], [f(x)], ms=4, color=:red)\n",
    "    if abs(old_x - x) <= tolerance\n",
    "        break\n",
    "    end\n",
    "end\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f949084-19ea-444d-9e4b-87986abf5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computational Cost:\n",
    "### L2-regularized Least Sqaures:\n",
    "For the L2-regularized least squares, running t iterations of gradient descent will take O(ndt), n examples and d features.\n",
    "The closed form solution: $w = (X^TX+\\lambda I)^{-1}(X^Ty)$, costs $O(nd^2 + d^3).\n",
    "\n",
    "So gradient descent is only faster if we only have to do $t <$ max$\\{d, d^2/n\\}$ iterations.\n",
    "\n",
    "### Logisitc Regression:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177787bb-5a5c-4538-940c-3ef6af778779",
   "metadata": {},
   "source": [
    "Test Cell adam is gonna put notes in\n",
    "\n",
    "https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf 477-498 are good  \n",
    "https://web.stanford.edu/~boyd/cvxbook/bv_cvxslides.pdf  \n",
    "https://www.osti.gov/servlets/purl/983240/  \n",
    "https://www.cs.ubc.ca/~schmidtm/Courses/540-W18/L4.pdf  \n",
    "https://www.math.usm.edu/lambers/mat419/lecture10.pdf  \n",
    "https://people.seas.harvard.edu/~yaron/AM221-S16/lecture_notes/AM221_lecture10.pdf  \n",
    "https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization  \n",
    "https://en.wikipedia.org/wiki/Hessian_matrix  \n",
    "https://en.wikipedia.org/wiki/Convex_function  \n",
    "https://www.cs.ubc.ca/~schmidtm/Courses/Notes/norms.pdf  \n",
    "  \n",
    "\n",
    "\n",
    "General steepest descent methods:\n",
    "    move along the direction that leads to the steepest descent with respect to a certain parameter\n",
    "\n",
    "starting at some intial point $x_0$, we iterate $x_k$ by stepping: \n",
    "$$\n",
    "x_{k+1} = x_k + \\alpha_kd_k\n",
    "$$\n",
    "\n",
    "where $d_k$ is the direction of steepest decrease in the function $f(x)$ and:\n",
    "\n",
    "$$\n",
    "\\alpha_k = \\arg_{\\alpha} \\min f(x_k + \\alpha d_k)\n",
    "$$\n",
    "\n",
    "ex for finding the minima of a function $h(x,y)$:\n",
    "$$\n",
    "f(x,y) = h(x,y)\n",
    "$$\n",
    "ex for finding the solution to an equation $Ax = b$:\n",
    "$$\n",
    "f(x_k) = ||Ax_k-b||\n",
    "$$\n",
    "ex for \n",
    "\n",
    "**Gradient descent**:https://en.wikipedia.org/wiki/Gradient_descent  \n",
    "    descend along the negative gradient of a function to find a local minima.  \n",
    "        requires the function to be differentiable.  \n",
    "    inverse is gradient ascent (finding maxima)\n",
    "   \n",
    "**Coordinate descent**:https://en.wikipedia.org/wiki/Coordinate_descent  \n",
    "    iteratively move along coordinate directions to find a local minima of a function  \n",
    "        does not require differentiability (big plus)  \n",
    "\n",
    "**Conjugate gradient descent**:https://en.wikipedia.org/wiki/Conjugate_gradient_method  \n",
    "\n",
    "\n",
    "**Adaptive coordinate descent**:https://en.wikipedia.org/wiki/Adaptive_coordinate_descent  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93da98b5-6b03-4e24-bbe7-82c6509a7a35",
   "metadata": {},
   "source": [
    "# Descent Methods #\n",
    "## Motivation: Unconstrained minimization problems ##\n",
    "Solving:\n",
    "$$\n",
    "\\min f(x)\n",
    "$$\n",
    "Where $f: \\Re^n \\rightarrow \\Re$. and f is continuously differentiable and has a minimum at the point $x_a$. To make our analysis easier (and ensure there is a minima), for this presentation we will also assume $f$ is **convex**.  \n",
    "### Convex functions ###\n",
    "A function $f$ is convex on an interval $x \\in [x_a,x_b]$ if:\n",
    "$$\n",
    "f(tx_1+(t-1)x_2) \\leq tf(x_1) + (1-t)f(x_2)\n",
    "$$\n",
    "for $t \\in [0,1]$ for any two points on the interval $x_1 \\in [x_a,x_b], x_2 \\in [x_a,x_b], x_1 < x_2$ . Graphically this is equivalent to:\n",
    "<div>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/ConvexFunction.svg/1024px-ConvexFunction.svg.png\" width=\"600\"/>\n",
    "</div>\n",
    "<em>Source: Wikipedia \"Convex Functions\"</em>\n",
    "for a function to be globally convex it must be true for any $x_1, x_2$. \n",
    "  \n",
    "If a function is convex then the global minimum will be at the point $x_{min}$ such that:\n",
    "$$\n",
    "\\nabla f(x_{min}) = 0\n",
    "$$\n",
    "\n",
    "an example of an important/useful function that are convex are norms.\n",
    "\n",
    "## Strong Convexity ##\n",
    "\n",
    "If a function is said to be strongly convex it satisfies:\n",
    "$$\n",
    "MI\\succeq \\nabla^2f(x)\\succeq mI\n",
    "$$\n",
    "$m, M > 0$. Which means the matrix $\\nabla^2f(x)$ is positive semi-definite ($x\\nabla^2f(x)x^T \\geq 0$). In 1 dimension this is equivalent to saying $f''(x) \\geq m$.\n",
    "##  Solving minimization problems: An intuitive approach ##\n",
    "Lets say we have some function $f: \\Re^2 \\rightarrow \\Re$ that we want to find the minimum of numerically, and we can differentiate the function at any point.\n",
    "  \n",
    "An intuitive pseudocode algorithm we could use would be as follows:  \n",
    "\n",
    "1. Starting at $x_0$, find the direction $\\Delta x$ which we can \"move\" from $x_0$ to decrease $f$ (descending)\n",
    "2. \"Move\" in that direction for \"a while\"\n",
    "3. Repeat steps 1 and 2 until we reach the minima\n",
    "\n",
    "This algorithm describes a generic **descent method**.  \n",
    "\n",
    "The direction $\\Delta x$ defines a line in $\\Re^2$ that we will move along.\n",
    "<div>\n",
    "<img src=\"steepestDescentSearchSlice.PNG\" width=\"400\"/>\n",
    "</div>\n",
    "The difference between descent methods often involve stopping at different points along the ray defined by the steepest descent line. Given a stopping condition, Step 2 in our algorithm becomes a **searching problem** as we will want to find the point at which we'd like stop along $\\Delta x$ to find the next direction of steepest descent.\n",
    "## Stopping conditions for Descent Method iteration steps ##\n",
    "Two commonly used searches are the **Linear search** and **Backtracking search**\n",
    "### Linear Search ###\n",
    "Evaluate:\n",
    "$$\n",
    "\\arg \\min_t f(x_0 + t\\Delta x)\n",
    "$$\n",
    "Or in $\\Re^2$, find the spot on the line defined by $x + t\\Delta x$ does the function reach a minima? This search method is **exact**. However, numerically this search method can be computationally depending on $f(x)$.\n",
    "\n",
    "### Backtracking search ###\n",
    "**Big idea:** Approximately minimize $f(x)$ along $\\Delta x$\n",
    "Start at $t_0 = 1$ and iterate $t_{n+1} = \\beta t_n$ until:\n",
    "$$\n",
    "f(x_0 +t_n\\Delta x) \\leq f(x_0) + \\alpha \\nabla f(x_0)^T \\Delta x\n",
    "$$\n",
    "Where $\\alpha \\in [0,0.5]$ and $\\beta \\in [0,1]$. This method is **inexact** but is useful for computation when it is costly to compute $f(x)$. Iterations of the descent method using backtracking converges on the minimum point slower than if using an exact search (fewer steps) but may execute faster if $f(x)$ is a costly operation.\n",
    "\n",
    "<div>\n",
    "<img src=\"backtrack.PNG\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "The reason this converges over many iterations to the minima hinges on the fact that $\\nabla f$ is monotonically approaching zero as we approach the minima since the function is convex. And that each step we take we get a little bit closer to the minima. Another way to see this is that there is a chord formed by the line $f(x_0)+\\alpha t\\nabla f(x_0)^T \\Delta x$ defines the region where the backtracking search can stop. Since $f$ is convex this chord is higher than all the other points between the points where the line intersects the function. This means that the search will only end when it has found a point that is lower than the initial point.\n",
    "\n",
    "## Example Steepest descent methods ##\n",
    "<div>\n",
    "<img src=\"steepestDescentSearch.PNG\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "## How do we determine the direction of steepest descent? ##\n",
    "The easiest option would be to move in the direction of the **negative gradient** of $f$ (the function we are minimizing):  \n",
    "$$\n",
    "\\Delta x = - \\nabla f(x)\n",
    "$$\n",
    "\n",
    "This would ensure that at each iteration we are always minimizing the distance between the minimized point $||f(x_{min}) - f(x_n)||_2$ at the maximal rate.\n",
    "<div>\n",
    "<img src=\"steepestDescentSearchShowingGrad.png\" width=\"500\"/>\n",
    "</div>\n",
    "The rays are always rotated $\\frac{\\pi}{2}$ radians from the level curves. This corresponds to following the negative gradient.\n",
    "\n",
    "## Are there other directions to descend? ##\n",
    "Yes! It depends on the norm we are using to minimize...\n",
    "1. Euclidan norm $||x||_2: -\\nabla f(x)$\n",
    "2. $\\textit{l}_1$-norm: $-(\\partial f(x)/\\partial(x_i))e_i$ where $|(\\partial f(x)/\\partial(x_i))| = ||\\nabla f(x)||_\\infty$\n",
    "3. $\\textit{l}_{\\infty}$-norm: $(-\\partial f(x)/\\partial(x_i))e_i$ where $x_i = ||f(x)_i||_\\infty$\n",
    "\n",
    "## Is this the best we can do? ##\n",
    "So far we have been only using 1st derivative information. What if we used higher order information as well?\n",
    "#### Newton's method for optimization ####\n",
    "Instead of using 1st derivative information to decide our step direction we can descend using the direction:\n",
    "$$\n",
    "\\Delta x = -\\frac{\\nabla f(x)}{\\nabla^2 f(x)}\n",
    "$$\n",
    "This gives the steepest descent direction to minimize the **Hessian norm** which is the matrix norm of the hessian matrix (contains all the 2nd order partials).  \n",
    "We will show that this converges faster in a moment. But once again, if the Hessian matrix cannot be computed or is costly to compute this method may execute slower.\n",
    "\n",
    "<div>\n",
    "<img src=\"newton_vs_grad.png\" width=\"400\"/>\n",
    "</div>\n",
    "Red shows Newton Step, green shows gradient descent (both with exact searches)  \n",
    "\n",
    "### Issues with Newton's method for optimization ###\n",
    "Along with the execution cost of the second derivatives required to compute the directions for this method, there are other drawbacks which can make Newton Step unusable:\n",
    "1. The Hessian matrix must be invertible (Used to calculate the descent direction)\n",
    "2. Can converge to a saddle point in $\\Re^n, n \\geq 2$\n",
    "3. Like the Newton method for root finding, it may not converge and instead oscillate between points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83977767-3a2f-48b3-88b8-d8e020e5b27c",
   "metadata": {},
   "source": [
    "## Convergence Analysis for Newton's Method for optimization ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d35b6e-8b31-48d1-9875-3f485a268e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1df21c73-2d16-45ae-af61-d61d92058e17",
   "metadata": {},
   "source": [
    "## Convergence Analysis for Gradient Descent ##\n",
    "\n",
    "**implications of strong convexity**\n",
    "\n",
    "Assume f is strongly convex on S, so that there exists $m,M$ such that $mI \\leq \\nabla^2 f(x) \\leq MI$ for all $x \\in S$.\n",
    "\n",
    "This also means that for $x,y \\in S$, we have:\n",
    "\n",
    "$f(y) = f(x) + \\nabla f(x)^T(y-x) + \\frac{1}2 (y-x)^T \\nabla^2 f(z) (y-x)$ for some z on the line segment between x and y.\n",
    "\n",
    "Plugging in the first inequality, we get for all $x,y \\in S$:\n",
    "\n",
    "$f(y) \\geq f(x) + \\nabla f(x)^T(y-x) + \\frac{m}2 ||y-x||_2^2$ (1)\n",
    "and similarly\n",
    "$f(y) \\leq f(x) + \\nabla f(x)^T(y-x) + \\frac{M}2 ||y-x||_2^2$ (2)\n",
    "\n",
    "Let $p^*$ be the minimum value of $f$, and we will show that $f-p^*$ is bounded. \n",
    "\n",
    "Setting the gradient of y to 0 (simple, omitted, calculus stuff), we can minimize the right hand side of (1) with $\\widetilde(y) = x - \\frac{1}m \\nabla f(x)$, such that:\n",
    "\n",
    "$f(y) \\geq f(x) + \\nabla f(x)^T(y-x) + \\frac{m}2 ||y-x||_2^2$\n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\geq f(x) + \\nabla f(x)^T(\\widetilde(y)-x) + \\frac{m}2 ||\\widetilde(y)-x||_2^2$ \n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\geq f(x) - \\frac{1}{2m} ||\\nabla f(x)||_2^2$ (just trust)\n",
    "\n",
    "This this holds for all $y \\in S$, we have:\n",
    "\n",
    "$\\frac{1}{2m} ||\\nabla f(x)||_2^2 \\geq f(x) - p^*$ (3)\n",
    "\n",
    "Now, back to the gradient descent:\n",
    "Define $g: \\Re \\to \\Re$, $g(t) = f(x - t\\nabla f(x))$, a function of the step length t in the negative gradient direction. Plugging in $y = x - t\\nabla f(x)$ above gets us a quadratic bound on g:\n",
    "\n",
    "$f(x - t\\nabla f(x)) = g(t) \\leq f(x) + t||\\nabla f(x)||_2^2 + \\frac{Mt^2}2 ||\\nabla f(x)||_2^2$\n",
    "\n",
    "**Analysis for linear search**\n",
    "\n",
    "Let $x^+ = x - t\\nabla f(x)$. Minimize both sides of the previous inequality:\n",
    "\n",
    "Let $t_{actual}$ be the step length that minimizes $g(t)$. and the right hand side be minimized by $t=1/M$, with a min value of $f(x) - \\frac{1}{2M} ||\\nabla f(x)||_2^2$. So, we get:\n",
    "\n",
    "$f(x^+) = g(t_{actual}) \\leq f(x) - \\frac{1}{2M} ||\\nabla f(x)||_2^2$\n",
    "\n",
    "Let $p^*$ be the minimum value of $f$, and subtract it from both sides.\n",
    "\n",
    "$f(x^+) - p^* \\leq f(x) - p^* - \\frac{1}{2M} ||\\nabla f(x)||_2^2$\n",
    "\n",
    "From (3), $||\\nabla f(x)||_2^2 \\geq 2m(f(x) - p^*)$, we get:\n",
    "\n",
    "$f(x^+) - p^* \\leq (1- \\frac{m}{M})(f(x) - p^*)$\n",
    "\n",
    "Let $c = 1- \\frac{m}{M} \\leq 1$, and apply the inequality above recursively, we get that:\n",
    "\n",
    "$f(x^{(k)}) - p^* \\leq c^{(k)}(f(x^{(0)}) - p^*)$\n",
    "\n",
    "Since as $k \\to 0$, $c^{(k)}(f(x^{(0)}) - p^*) \\to 0$, we see that $f(x^{(k)})$ converges to $p^*$, the minimum value of $f$.\n",
    "4\n",
    "In particular, we will have $f(x^{(k)}) - p^* < \\epsilon$ after at most $\\frac{log(\\frac{(f(x^{(0)}) - p^*)}{\\epsilon})}{log(\\frac{1}{c})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a87a7aa-4cea-4c3d-9073-b13ec5e46186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
