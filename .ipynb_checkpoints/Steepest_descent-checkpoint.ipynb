{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f20197-6a8a-4ebd-abe3-456903fbfbbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MATH 405/607 \n",
    "\n",
    "# Method of Steepest Descent \n",
    "# (Also known as Gradient Descent)\n",
    "\n",
    "* Optimization problems & Root finding\n",
    "* Gradient Descent Scheme\n",
    "* Error Analysis\n",
    "* Global Convergence\n",
    "\n",
    "### Literature \n",
    "\n",
    "* [Boyd and Vandenberghe, Convex Optimization, Chapter 9](https://web.stanford.edu/~boyd/cvxbook/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "795cc739-e637-42f9-9e6b-32ca679c17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module MATH405.\n"
     ]
    }
   ],
   "source": [
    "include(\"math405.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f424287f-c4ae-4d9e-9972-a3d37543a384",
   "metadata": {},
   "source": [
    "## Optimization Problems\n",
    "\n",
    "**Motivation:** Finding the minimum (\"optimum\") points of a function numerically. \n",
    "\n",
    "**Fundamental Principle:** By following the opposite direction of its gradient in each iteration.\n",
    "\n",
    "In other words, step towards where the function decreases the fastest. (\"Steepest\" descent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3464777-4d52-4fbe-858c-0b24ffa8029e",
   "metadata": {},
   "source": [
    "Simple example:\n",
    "\n",
    "Finding the minimum of\n",
    "$$f(x,y) = x^2 + y^2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d29679-27f3-49fa-a6c7-1af25960d686",
   "metadata": {},
   "source": [
    "![GradientDescenturl](https://blog.paperspace.com/content/images/2018/05/68747470733a2f2f707669676965722e6769746875622e696f2f6d656469612f696d672f70617274312f6772616469656e745f64657363656e742e676966.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d22e5c2-7a7a-43ee-b841-a2c9f3e1fc89",
   "metadata": {},
   "source": [
    "### Formulation\n",
    "Given a function $f \\in \\mathbb{R}^M$, which we need to find its minimum.\n",
    "\n",
    "Starting at some initial guess: $U_0 = \\begin{pmatrix} \n",
    "    x_{1, 0} \\\\ x_{2, 0} \\\\ \\vdots \\\\ x_{M, 0}\n",
    "    \\end{pmatrix}$\n",
    "\n",
    "The gradient of the function at this point is given by \n",
    "$$\\nabla f(U_n)= \n",
    "    \\begin{pmatrix} \n",
    "    \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_M}\n",
    "    \\end{pmatrix} \\, \\Bigg|_{\\,U_n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2b305-3cbc-4b7d-8b16-6e5c77f4a522",
   "metadata": {},
   "source": [
    "Then, we define the Gradient Descent Scheme:\n",
    "\n",
    "$$ U_{n+1} = U_n + h\\big( -\\nabla f(U_n)\\big)$$\n",
    "\n",
    "Where $h$ is the step size\n",
    "\n",
    "With the exit condition being $\\lVert \\nabla f(U_k) \\rVert \\leq \\epsilon$ for some small tolerance $\\epsilon$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab240f21-13b1-4278-8263-cea0785c0db7",
   "metadata": {},
   "source": [
    "### Advantage of the Gradient Descent Scheme:\n",
    "\n",
    "* Resilient to not so \"nice\" functions (Whose higher order derivatives does not exist or have unwanted zeros)\n",
    "* Moderate computation complexity (Requires only first order derivative)\n",
    "* Consistent convergence rate & Globally convergent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95768c7f-c4e7-4e4a-80c3-ea686ed05f08",
   "metadata": {},
   "source": [
    "### Comparison to Newton's Method in Optimization ï¼ˆ1-D Case)\n",
    "The Newton's Method of Optimization is defined as \n",
    "$$U_{n+1} = U_n - h\\frac{f'(U_n)}{f''(U_n)}$$\n",
    "(Finding the root of derivative instead of $f^0(x)$)\n",
    "\n",
    "Where the 1-D Gradient Descent Method is \n",
    "$$ U_{n+1} = U_n - hf'(U_n)$$\n",
    "\n",
    "Newton's Method requires $f''(U_n)$ to exist and is well-behaved (no nearby zeros)\n",
    "\n",
    "Where Gradient Descent only requires $f'(U_n)$ to exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d82c08-febc-426a-bc20-63673d613b2b",
   "metadata": {},
   "source": [
    "### Example:\n",
    "Finding the minimum of $f(x) = cos(x)$ within $(0, \\pi)$ \n",
    "\n",
    "##### Newton's Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a34651f-fee1-4bf7-bebf-c0412f861011",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x -> cos(x)\n",
    "df = x -> ForwardDiff.derivative(f, x)\n",
    "d2f = x -> ForwardDiff.derivative(df, x)\n",
    "h = 0.01\n",
    "tolerance = 1e-8;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1507ff34-d43e-4e9a-8d9a-1cd103fe87db",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: plot not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: plot not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[1]:6",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "#guess = pi/2+0.00001 # If you QA Engineer is having a bad day he's gonna do this\n",
    "#Believe or not, this ^^ is so ugly that even Jupyter Lab refused to save the notebook file (throws error 413)\n",
    "guess = pi/2 + 0.1\n",
    "\n",
    "x = guess; iter = [x]\n",
    "p = plot(f, 0.0, 2*pi, lw=3, grid=:xy, size=(800,300))\n",
    "scatter!([x], [f(x)], ms=4, color=:red)\n",
    "while(true)\n",
    "    old_x = x\n",
    "    x -= h * df(x) / d2f(x) ; push!(iter, x)\n",
    "    scatter!([x], [f(x)], ms=4, color=:red)\n",
    "    if abs(old_x - x) <= tolerance\n",
    "        break\n",
    "    end\n",
    "end\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d1df0-2ce0-42f6-a41a-9a927f165d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = pi/2+0.5\n",
    "\n",
    "x = guess; iter = [x]\n",
    "p = plot(f, 0.0, 2*pi, lw=3, grid=:xy, size=(800,300))\n",
    "scatter!([x], [f(x)], ms=4, color=:red)\n",
    "while(true)\n",
    "    old_x = x\n",
    "    x -= h * df(x) ; push!(iter, x)\n",
    "    scatter!([x], [f(x)], ms=4, color=:red)\n",
    "    if abs(old_x - x) <= tolerance\n",
    "        break\n",
    "    end\n",
    "end\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f949084-19ea-444d-9e4b-87986abf5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computational Cost:\n",
    "### L2-regularized Least Sqaures:\n",
    "For the L2-regularized least squares, running t iterations of gradient descent will take O(ndt), n examples and d features.\n",
    "The closed form solution: $w = (X^TX+\\lambda I)^{-1}(X^Ty)$, costs $O(nd^2 + d^3).\n",
    "\n",
    "So gradient descent is only faster if we only have to do $t <$ max$\\{d, d^2/n\\}$ iterations.\n",
    "\n",
    "### Logisitc Regression:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177787bb-5a5c-4538-940c-3ef6af778779",
   "metadata": {},
   "source": [
    "Test Cell adam is gonna put notes in\n",
    "\n",
    "https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf 477-498 are good  \n",
    "https://web.stanford.edu/~boyd/cvxbook/bv_cvxslides.pdf  \n",
    "https://www.osti.gov/servlets/purl/983240/  \n",
    "https://www.cs.ubc.ca/~schmidtm/Courses/540-W18/L4.pdf  \n",
    "https://www.math.usm.edu/lambers/mat419/lecture10.pdf  \n",
    "https://people.seas.harvard.edu/~yaron/AM221-S16/lecture_notes/AM221_lecture10.pdf  \n",
    "\n",
    "\n",
    "General steepest descent methods:\n",
    "    move along the direction that leads to the steepest descent with respect to a certain parameter\n",
    "\n",
    "starting at some intial point $x_0$, we iterate $x_k$ by stepping: \n",
    "$$\n",
    "x_{k+1} = x_k + \\alpha_kd_k\n",
    "$$\n",
    "\n",
    "where $d_k$ is the direction of steepest decrease in the function $f(x)$ and:\n",
    "\n",
    "$$\n",
    "\\alpha_k = \\arg_{\\alpha} \\min f(x_k + \\alpha d_k)\n",
    "$$\n",
    "\n",
    "ex for finding the minima of a function $h(x,y)$:\n",
    "$$\n",
    "f(x,y) = h(x,y)\n",
    "$$\n",
    "ex for finding the solution to an equation $Ax = b$:\n",
    "$$\n",
    "f(x_k) = ||Ax_k-b||\n",
    "$$\n",
    "ex for \n",
    "\n",
    "**Gradient descent**:https://en.wikipedia.org/wiki/Gradient_descent  \n",
    "    descend along the negative gradient of a function to find a local minima.  \n",
    "        requires the function to be differentiable.  \n",
    "    inverse is gradient ascent (finding maxima)\n",
    "   \n",
    "**Coordinate descent**:https://en.wikipedia.org/wiki/Coordinate_descent  \n",
    "    iteratively move along coordinate directions to find a local minima of a function  \n",
    "        does not require differentiability (big plus)  \n",
    "\n",
    "**Conjugate gradient descent**:https://en.wikipedia.org/wiki/Conjugate_gradient_method  \n",
    "\n",
    "\n",
    "**Adaptive coordinate descent**:https://en.wikipedia.org/wiki/Adaptive_coordinate_descent  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93da98b5-6b03-4e24-bbe7-82c6509a7a35",
   "metadata": {},
   "source": [
    "# Descent Methods #\n",
    "## Motivation: Unconstrained minimization problems ##\n",
    "Solving:\n",
    "$$\n",
    "\\min f(x)\n",
    "$$\n",
    "Where $f: \\Re^n \\rightarrow \\Re$. and f is continuously differentiable and has a minimum at the point $x_a$. To make our analysis easier (and ensure there is a minima), for this presentation we will aslo assume $f$ is **convex**.  \n",
    "### Convex functions ###\n",
    "A function $f$ is convex on an interval $x \\in [x_1,x_2]$ if:\n",
    "$$\n",
    "f(tx_1+(t-1)x_2) \\leq tf(x_1) + (1-t)f(x_2)\n",
    "$$\n",
    "for $t \\in [0,1]$. Graphically this is equivalent to:\n",
    "![Convex Chord](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/ConvexFunction.svg/1024px-ConvexFunction.svg.png)\n",
    "<em>Source: Wikipedia \"Convex Functions\"</em>\n",
    "for a function to be globally convex it must be true for any $x_1, x_2$. \n",
    "  \n",
    "If a function is convex then the global minimum will be at the point $x_{min}$ such that:\n",
    "$$\n",
    "\\nabla f(x_{min}) = 0\n",
    "$$\n",
    "\n",
    "an example of an important/useful function that are convex are norms.\n",
    "## Solving minimization problems: An intuitive approach ##\n",
    "Lets say we have some function $f: \\Re^2 \\rightarrow \\Re$ that we want to find the minimum of numerically, and we can differentiate the function at any point.\n",
    "  \n",
    "An intuitive pseudocode algorithm we could use would be as follows:  \n",
    "\n",
    "1. Starting at $x_0$, find the direction $\\Delta x$ which we can \"move\" from $x_0$ to decrease $f$ the fastest (steepest descent)\n",
    "2. \"Move\" in that direction for \"a while\"\n",
    "3. Repeat steps 1 and 2 until we reach the minima\n",
    "\n",
    "This algorithm describes a generic **steepest descent method**.  \n",
    "\n",
    "The direction $\\Delta x$ defines a line in $\\Re^2$ that we will move along.\n",
    "![Steepest Descent Searches](steepestDescentSearchSlice.PNG)\n",
    "\n",
    "The difference between descent methods often involve stopping at different points along the ray defined by the steepest descent line. Given a stopping condition, Step 2 in our algorithm becomes a **searching problem** as we will want to find the point at which we'd like stop along $\\Delta x$ to find the next direction of steepest descent.\n",
    "## Stopping conditions for Steepest Descent Method iteration steps ##\n",
    "Two commonly used searches are the **Linear search** and **Backtracking search**\n",
    "### Linear Search ###\n",
    "Evaluate:\n",
    "$$\n",
    "\\arg \\min_t f(x_0 + t\\Delta x)\n",
    "$$\n",
    "Or in $\\Re^2$, find the spot on the line defined by $x + t\\Delta x$ does the function reach a minima? This search method is **exact**. However, numerically this search method can be computationally depending on $f(x)$.\n",
    "\n",
    "### Backtracking search ###\n",
    "**Big idea:** Approximately minimize $f(x)$ along $\\Delta x$\n",
    "$$\n",
    "\\arg \\min_t f(x_0 + t\\Delta x)\n",
    "$$\n",
    "Or find the spot on the slice defined by $x + t\\Delta x$ does the function reach a minima?\n",
    "\n",
    "## Example Steepest descent methods ##\n",
    "![Steepest Descent Searches](steepestDescentSearch.PNG)\n",
    "\n",
    "## How do we determine the direction of steepest descent? ##\n",
    "The easiest option would be to move in the direction $\\Delta x$ of the **negative gradient** of $f$ (the function we are minimizing):  \n",
    "$$\n",
    "\\Delta x = - \\nabla f(x)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d35b6e-8b31-48d1-9875-3f485a268e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
